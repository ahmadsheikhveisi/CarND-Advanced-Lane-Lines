{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def store_img(img,dstfldr,filename,extra):\n",
    "    if filename is '':\n",
    "        return\n",
    "    if dstfldr != '':\n",
    "        dstfldr = \"output_images\" + '/' + dstfldr\n",
    "    else:\n",
    "        dstfldr = 'output_images'\n",
    "    (head, tail) = os.path.split(filename)\n",
    "    (root, ext) = os.path.splitext(tail)\n",
    "    new_filename = os.path.join(dstfldr, root + extra + \".jpg\")\n",
    "    cv2.imwrite(new_filename, img)\n",
    "\n",
    "# from https://stackoverflow.com/questions/42420470/opencv-subplots-images-with-titles-and-space-around-borders\n",
    "def cvSubplot(imgs,     # 2d np array of imgs (each img an np arrays of depth 1 or 3).\n",
    "              pad=50,   # number of pixels to use for padding between images. must be even\n",
    "              titles=None,  # (optional) np array of subplot titles\n",
    "              ):\n",
    "    '''\n",
    "    Makes cv2 based subplots. Useful to plot image in actual pixel size\n",
    "    '''\n",
    "    rows = np.shape(imgs)[0]\n",
    "    cols = np.shape(imgs)[1]\n",
    "\n",
    "    subplot_shapes = np.array([list(map(np.shape, x)) for x in imgs])\n",
    "    sp_height, sp_width, depth = np.max(np.max(subplot_shapes, axis=0), axis=0)\n",
    "\n",
    "    title_pad = 50\n",
    "    if titles is not None:\n",
    "        pad_top = pad + title_pad\n",
    "    else:\n",
    "        pad_top = pad\n",
    "\n",
    "    frame = np.ones((rows*(sp_height+pad_top), cols*(sp_width+pad), depth )) * 255\n",
    "\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            img = imgs[r, c]\n",
    "            h, w, _ = img.shape\n",
    "            y0 = r * (sp_height+pad_top) + pad_top//2\n",
    "            x0 = c * (sp_width+pad) + pad//2\n",
    "            frame[y0:y0+h, x0:x0+w, :] = img\n",
    "\n",
    "            if titles is not None:\n",
    "                frame = cv2.putText(frame, titles[r, c], (x0 + w//2, y0-title_pad//4), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "\n",
    "    return frame\n",
    "    \n",
    "def undist(img, mtx, dist, filename = '',dstfldr = ''):\n",
    "    \n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    #print(\"image_size \",img_size)\n",
    "    # Distortion Correction\n",
    "    undist = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    imgs = np.array([[img,undist]])\n",
    "    ttls = np.array([['original','undistorted']])\n",
    "    store_img(cvSubplot(imgs,titles=ttls),dstfldr,filename,\"_undistorted\")   \n",
    "    \n",
    "    return undist \n",
    "\n",
    "def unwarp(img, src, dst, filename = '',dstfldr=''):\n",
    "    \n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    imgs = np.array([[img,warped]])\n",
    "    ttls = np.array([['original','warped']])\n",
    "    store_img(cvSubplot(imgs,titles=ttls),dstfldr,fname,\"_warped\")  \n",
    "    \n",
    "    return warped, M, Minv\n",
    "\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0,255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) the input image must be in grayscale\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    binary_output = np.copy(img) # Remove this line\n",
    "    if ((orient is not 'x') and (orient is not 'y')):\n",
    "        return None\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "    gray = np.copy(img)\n",
    "    sobelx = cv2.Sobel(gray,cv2.CV_64F,(0,1)[orient == 'x'],(0,1)[orient == 'y'],ksize=sobel_kernel)\n",
    "    abs_sobel = np.absolute(sobelx)\n",
    "    abs_sobel_scale = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(abs_sobel_scale)\n",
    "    binary_output[(abs_sobel_scale >= thresh_min) & (abs_sobel_scale <= thresh_max)] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) the input image must be in grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Calculate the magnitude \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    gray = np.copy(img)\n",
    "    sobelx = cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    mag_sobel = np.sqrt(np.square(sobelx)+np.square(sobely))\n",
    "    mag_scaled = np.uint8(255*mag_sobel/np.max(mag_sobel))\n",
    "    binary_output = np.zeros_like(mag_scaled)\n",
    "    binary_output[(mag_scaled >= mag_thresh[0]) & (mag_scaled <= mag_thresh[1])] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) the input image must be in grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    gray = np.copy(img)\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=sobel_kernel))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=sobel_kernel))\n",
    "    direction = np.arctan2(abs_sobely,abs_sobelx)\n",
    "    binary_output = np.zeros_like(gray)\n",
    "    binary_output[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the object and image points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nx = 9\n",
    "ny = 6\n",
    "camera_image_size = cv2.cvtColor(cv2.imread(\"test_images/test1.jpg\"),cv2.COLOR_BGR2GRAY).shape\n",
    "#print(camera_image_size)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "calib_images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in calib_images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img_corners = cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "        store_img(img_corners,\"CameraCalibration/Corners\",fname,\"_corners\")\n",
    "points_pickle = {\"objpoints\":objpoints,\"imgpoints\":imgpoints}\n",
    "with open('ObjImagePoints_pickle.pickle', 'wb') as f:\n",
    "    pickle.dump(points_pickle, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the camera matrix and distortion coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints,imgpoints,(camera_image_size[1],camera_image_size[0]),None,None)\n",
    "\n",
    "dist_pickle = {\"camMtrx\":mtx,\"distCoe\":dist}\n",
    "with open('CameraMatrix_DistrotionCoefficients.pickle', 'wb') as f:\n",
    "    pickle.dump(dist_pickle, f)\n",
    "\n",
    "for index,fname in enumerate(calib_images):\n",
    "    undist_image = undist(cv2.imread(fname),mtx,dist,fname,\"CameraCalibration/Undistorted\")\n",
    "    # Convert to gray-scale\n",
    "    gray = cv2.cvtColor(undist_image, cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    if (ret == True):\n",
    "        cv2.drawChessboardCorners(undist_image, (nx, ny), corners, ret)\n",
    "        #print(\"CORNERS \",corners)\n",
    "        src = np.float32([corners[0],corners[nx-1],corners[((ny-1)*nx)],corners[(nx*ny)-1]])\n",
    "        #print(\"SRC\",src)\n",
    "        dst = np.float32([[100,100],[1200,100],[100,600],[1200,600]])\n",
    "        warped_image,M,Minv = unwarp(undist_image,src,dst,fname,\"CameraCalibration/Warped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Applying the distortion correction to the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist_pickle = pickle.load( open( \"CameraMatrix_DistrotionCoefficients.pickle\", \"rb\" ) )\n",
    "p_mtx = dist_pickle[\"camMtrx\"]\n",
    "p_dist = dist_pickle[\"distCoe\"]\n",
    "\n",
    "sobel_kernel_size=3\n",
    "\n",
    "s_thresh=(170, 255)\n",
    "sx_thresh=(20, 100)\n",
    "sm_thresh=(30, 100)\n",
    "sd_thresh=(0.7, 1.3)\n",
    "\n",
    "def advanced_pipeline(img,filename=''):\n",
    "    undist_image = undist(img,p_mtx,p_dist,filename)\n",
    "    \n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(undist_image, cv2.COLOR_BGR2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    #print(l_channel.shape)\n",
    "    gradx = abs_sobel_thresh(l_channel, orient='x', sobel_kernel=sobel_kernel_size, thresh=sx_thresh)\n",
    "    grady = abs_sobel_thresh(l_channel, orient='y', sobel_kernel=sobel_kernel_size, thresh=sx_thresh)\n",
    "    mag_binary = mag_thresh(l_channel, sobel_kernel=sobel_kernel_size, mag_thresh=sm_thresh)\n",
    "    dir_binary = dir_threshold(l_channel, sobel_kernel=sobel_kernel_size, thresh=sd_thresh)\n",
    "    \n",
    "    grad_combined = np.zeros_like(dir_binary)\n",
    "    grad_combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    #print(grad_combined.shape)\n",
    "    #plt.imshow(grad_combined, cmap='gray')\n",
    "    #plt.show()\n",
    "    store_img(grad_combined*255,'',filename,\"_gradThrsh\")\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    #plt.imshow(s_binary, cmap='gray')\n",
    "    #plt.show()\n",
    "    store_img(s_binary*255,'',filename,\"_clrThrsh\")\n",
    "    \n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( s_binary, grad_combined, np.zeros_like(grad_combined))) * 255\n",
    "    \n",
    "    store_img(color_binary,'',filename,\"_clrGradThrsh\")\n",
    "    \n",
    "    binary_mask = np.zeros_like(s_binary)\n",
    "    store_img(color_binary,'',filename,\"_clrGradThrsh\")\n",
    "    \n",
    "    return color_binary\n",
    "\n",
    "test_images = os.listdir(\"test_images/\")\n",
    "for img in test_images:\n",
    "    img = \"test_images/\" + img\n",
    "    out_image = advanced_pipeline(cv2.imread(img),img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
